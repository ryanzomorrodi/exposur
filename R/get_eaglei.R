eaglei_url <- "https://figshare.com/ndownloader/articles/24237376/versions/2"
census_susb_url <- "https://www2.census.gov/programs-surveys/susb/tables/{year}/county_3digitnaics_{year}.xlsx"
eia_url <- "https://www.eia.gov/electricity/data/browser/data/index.php?method=getMapData&geosetId=ELEC.CUSTOMERS.ALL.M&freq=M&topic=56"

download_acs_households <- function(year) {
  tidycensus::get_acs(
    "county",
    "B11001_001",
    year = year + 2,
    output = "wide"
  )
}

download_susb_establishments <- function(year) {
  susb_file <- tempfile(fileext = ".xlsx")
  curl::curl_download(stringr::str_glue(census_susb_url), susb_file)

  readxl::read_excel(susb_file, skip = 2) |>
    dplyr::filter(.data$`NAICS Description` == "Total") |>
    dplyr::filter(.data$`Enterprise Size` == "1: Total") |>
    dplyr::mutate("GEOID" = stringr::str_c(.data$State, .data$County))
}

download_eia_customers <- function(year) {
  eia_body <- httr2::request(eia_url) |>
    httr2::req_perform() |>
    httr2::resp_body_json()

  eia_data <- tibble::tibble(body = purrr::pluck(eia_body, 2)) |>
    tidyr::unnest_wider(body)
  eia_dates <- tibble::tibble(month = unlist(purrr::pluck(eia_body, 1)))

  state_fips <- dplyr::distinct(
    tidycensus::fips_codes,
    .data$state,
    .data$state_code
  )

  dplyr::bind_cols(eia_dates, eia_data) |>
    tidyr::pivot_longer(
      !c("month"), 
      names_to = "state",
      values_to = "customers"
    ) |>
    dplyr::mutate(state = stringr::str_remove(.data$state, "US-")) |>
    dplyr::filter(stringr::str_sub(.data$month, 1, 4) == year) |>
    dplyr::group_by(.data$state) |>
    dplyr::summarize("customers" = mean(.data$customers)) |>
    dplyr::left_join(state_fips, "state")
}

calc_customer_est <- function(year, path) {
  file_name <- stringr::str_c(year, "_customer_est.csv")

  if (is.null(path)) {
    file_path <- stringr::str_c(tempdir(), file_name, sep = "/")
  } else {
    file_path <- stringr::str_c(path, file_name, sep = "/")
  }

  if (!file.exists(file_path)) {
    establishment_count <- download_susb_establishments(year)
    household_count <- download_acs_households(year)
    total_count <- establishment_count |>
      dplyr::left_join(household_count, "GEOID") |>
      dplyr::mutate(
        "hld_est" = .data$Establishments + .data$B11001_001E
      ) |>
      dplyr::select(c("GEOID", "hld_est")) |>
      dplyr::filter(stringr::str_sub(.data$GEOID, 3, 5) != "999") |>
      dplyr::mutate("state_code" = stringr::str_sub(.data$GEOID, 1, 2)) |>
      dplyr::group_by(.data$state_code) |>
      dplyr::mutate("customer_pct" = .data$hld_est / sum(.data$hld_est)) |>
      dplyr::ungroup()

    eia_customers <- download_eia_customers(year)

    total_count |>
      dplyr::left_join(eia_customers, "state_code") |>
      dplyr::mutate("customers" = .data$customers * .data$customer_pct) |>
      dplyr::select(c("geoid" = "GEOID", "customers")) |>
      readr::write_csv(file_path)
  }

  readr::read_csv(file_path)
}

download_eaglei <- function(path) {
  if (is.null(path)) {
    file_path <- stringr::str_c(tempdir(), "eaglei.zip", sep = "/")
  } else {
    file_path <- stringr::str_c(path, "eaglei.zip", sep = "/")
  }

  if (!file.exists(file_path)) {
    cat("The eaglei zip file is 8+ GB, so this will take some time.\n")
    cat(stringr::str_c("Downloading to: ", file_path, "\n"))

    response <- httr2::request(eaglei_url) |>
      httr2::req_perform(path = file_path)
  }

  file_path
}

#' Download and Filter Outage Data
#'
#' @description
#' Downloadeds publically available EAGLE-I data published
#' by [Brelsford et al.](https://www.nature.com/articles/s41597-024-03095-5)
#'
#' @details
#' ## Customer Estimates
#' Customer estimates are generated by adding the number of households
#' (ACS centered on year of storm) and number of establishments (Census SUBI
#' for year of storm) per county, getting the percentage of households and
#' establishments per county by state, and multiplying the percentage by the
#' total number of customers in a county (EIA average over year of storm)
#'
#' @param interval Dates to get outage data for
#' @param path Path to download files into (if not provided,
#' files will be download into the `tempdir()`)
#'
#' @return Maximum precentage and average duration of outage
#' by county
#' @export
#'
#' @examples
#' \dontrun{
#' harvey_eaglei <- get_eaglei(
#'   interval = interval(harvey_start, harvey_end + days(5)),
#'   path = "raw-data/eaglei"
#' )
#' }
get_eaglei <- function(interval, path = NULL) {
  eaglei_path <- download_eaglei(path)

  year <- lubridate::year(lubridate::int_start(interval))

  customer_est <- calc_customer_est(year, path)

  readr::read_csv(unz(
    eaglei_path,
    stringr::str_c("eaglei_outages_", year, ".csv")
  )) |>
    dplyr::filter(.data$run_start_time %within% interval) |>
    dplyr::full_join(x = customer_est, by = c("geoid" = "fips_code")) |>
    dplyr::relocate("customers", .after = "customers_out")
}
